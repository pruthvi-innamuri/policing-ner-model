{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a31bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import spacy\n",
    "from os.path import exists\n",
    "from spacy.tokens import DocBin\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d28922",
   "metadata": {},
   "source": [
    "Experimentation with a Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da3af0cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Begin Offset</th>\n",
       "      <th>End Offset</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>CASE NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>97</td>\n",
       "      <td>OFFICER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>81</td>\n",
       "      <td>88</td>\n",
       "      <td>OFFICER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>OFFICER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>56</td>\n",
       "      <td>63</td>\n",
       "      <td>OFFICER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>55</td>\n",
       "      <td>62</td>\n",
       "      <td>OFFICER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>91</td>\n",
       "      <td>98</td>\n",
       "      <td>OFFICER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>OFFICER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22</td>\n",
       "      <td>75</td>\n",
       "      <td>89</td>\n",
       "      <td>SUBJECT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23</td>\n",
       "      <td>53</td>\n",
       "      <td>60</td>\n",
       "      <td>OFFICER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>OFFICER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27</td>\n",
       "      <td>67</td>\n",
       "      <td>82</td>\n",
       "      <td>SUBJECT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "      <td>47</td>\n",
       "      <td>54</td>\n",
       "      <td>OFFICER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>OFFICER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>38</td>\n",
       "      <td>98</td>\n",
       "      <td>105</td>\n",
       "      <td>OFFICER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>OFFICER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>DATE OF OCCURRENCE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Line  Begin Offset  End Offset                Type\n",
       "0      3             0          13         CASE NUMBER\n",
       "1      9            90          97             OFFICER\n",
       "2     10            81          88             OFFICER\n",
       "3     12            22          29             OFFICER\n",
       "4     13            56          63             OFFICER\n",
       "5     14            55          62             OFFICER\n",
       "6     16            91          98             OFFICER\n",
       "7     19            19          26             OFFICER\n",
       "8     22            75          89             SUBJECT\n",
       "9     23            53          60             OFFICER\n",
       "10    26             0           7             OFFICER\n",
       "11    27            67          82             SUBJECT\n",
       "12    36            47          54             OFFICER\n",
       "13    37            28          35             OFFICER\n",
       "14    38            98         105             OFFICER\n",
       "15    40             9          16             OFFICER\n",
       "16    48             0          10  DATE OF OCCURRENCE"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Pruthvi\\Desktop\\trainingannotations\\2014-20335_Case_Report_-_Redacted00001-10.jpg.txt.csv\")\n",
    "df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28779f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#open file\n",
    "file = open(r\"C:\\Users\\Pruthvi\\Desktop\\output\\2014-20335_Case_Report_-_Redacted00001-01.jpg.txt\")\n",
    "training_data = list([])\n",
    "\n",
    "#get dataframe\n",
    "df = pd.read_csv(r\"C:\\Users\\Pruthvi\\Desktop\\trainingannotations\\2014-20335_Case_Report_-_Redacted00001-01.jpg.txt.csv\")\n",
    "\n",
    "#get relevant line numbers and words' offsets\n",
    "allLines = df['Line']\n",
    "bo = df['Begin Offset']\n",
    "eo = df['End Offset']\n",
    "labels = df['Type']\n",
    "counter = 0\n",
    "\n",
    "#loop through the file's lines and get the words\n",
    "for LIndex, L in enumerate(file.readlines()):\n",
    "    if LIndex  == allLines[counter]:\n",
    "        temp = tuple((L, [(bo[counter],eo[counter],labels[counter])]))\n",
    "        training_data.append(temp)\n",
    "        counter+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e5ac9",
   "metadata": {},
   "source": [
    "The Actual Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64ac1f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = list([])\n",
    "\n",
    "directory = r\"C:\\Users\\Pruthvi\\Desktop\\output\"\n",
    "for file_name in os.listdir(directory):\n",
    "    if exists(r\"C:\\Users\\Pruthvi\\Desktop\\trainingannotations\\\\\" + file_name + \".csv\"):\n",
    "        #print(\"New File\")\n",
    "        \n",
    "        #open file\n",
    "        file = open(r\"C:\\Users\\Pruthvi\\Desktop\\output\\\\\" + file_name)\n",
    "        #print(file_name)\n",
    "        \n",
    "        #get dataframe\n",
    "        df = pd.read_csv(r\"C:\\Users\\Pruthvi\\Desktop\\trainingannotations\\\\\" + file_name + \".csv\").sort_values(by=\"Line\", ascending=True)\n",
    "        df_length = len(df)\n",
    "        df = df.sort_values(by=\"Line\", ascending=True)\n",
    "        df.index = range(df_length)\n",
    "        #print(df_length)\n",
    "        #print(\"\")\n",
    "\n",
    "        #if the dataframe is empty\n",
    "        if df_length ==0:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        #get relevant line numbers and words' offsets\n",
    "        allLines = df['Line']\n",
    "        bo = df['Begin Offset']\n",
    "        eo = df['End Offset']\n",
    "        labels = df['Type']\n",
    "        counter = 0\n",
    "\n",
    "        #loop through the file's lines and get the words\n",
    "        for LIndex, L in enumerate(file.readlines()):\n",
    "            #print(\"Counter:\" + str(counter))\n",
    "            #print(\"Index:\" + str(LIndex))\n",
    "            #print(\"Next Line Number:\" + str(allLines[counter]))\n",
    "            if LIndex == allLines[counter]:\n",
    "                #print('Index in')\n",
    "                temp = tuple((L, [(bo[counter],eo[counter],labels[counter])]))\n",
    "                training_data.append(temp)\n",
    "                #print(training_data[len(training_data)-1])\n",
    "                \n",
    "                if counter+1 < df_length:\n",
    "                    if allLines[counter+1] > allLines[counter]:\n",
    "                        counter+=1\n",
    "                    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ca2ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomize the data before we split it for training and validation\n",
    "random.shuffle(training_data)\n",
    "\n",
    "#Calculate split point\n",
    "split_position = int(len(training_data)*0.7)\n",
    "\n",
    "#Create training and validation sets\n",
    "validation = training_data[split_position:]\n",
    "training = training_data[:split_position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9f94192",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "#Saving Training data to .spacy format file\n",
    "db = DocBin()\n",
    "for text, annotations in training:\n",
    "    doc = nlp(text)\n",
    "    ents = []\n",
    "    for start, end, label in annotations:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span != None:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./train.spacy\")\n",
    "\n",
    "\n",
    "# Saving Validation data to .spacy format file\n",
    "db = DocBin()\n",
    "for text, annotations in validation:\n",
    "    doc = nlp(text)\n",
    "    ents = []\n",
    "    for start, end, label in annotations:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span != None:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./valid.spacy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44c19e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a base config file on spacy website and download\n",
    "\n",
    "#Add paths to training and validation sets in base config file and convert to regular config file\n",
    "#python -m spacy init fill-config base_config.cfg config.cfg\n",
    "\n",
    "#Train the model\n",
    "#python -m spacy train config.cfg --output ./ner_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33b81987",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = spacy.load(\"ner_model/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58d13ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204805"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get predictions for Santa Maria Data\n",
    "SantaMaria = r\"C:\\Users\\Pruthvi\\Desktop\\policingnotebook\\Training Data\\Santa Maria PD\\txt\"\n",
    "SantaMariaPredictions = []\n",
    "for file_name in os.listdir(SantaMaria):\n",
    "    file = open(SantaMaria + \"\\\\\" + file_name)\n",
    "    try: \n",
    "        textarr = file.readlines()\n",
    "        textstring = ner(\" \".join(textarr))\n",
    "\n",
    "        predictions = [\"FILE NAME: \" + file_name]\n",
    "        for ent in textstring.ents:\n",
    "            \n",
    "            predictions += [[ent.text, ent.label_]]\n",
    "\n",
    "        SantaMariaPredictions += [predictions]\n",
    "    \n",
    "    except(UnicodeDecodeError):\n",
    "        continue\n",
    "\n",
    "#Save predictions to txt file\n",
    "SM_txt = open(r\"C:\\Users\\Pruthvi\\Desktop\\policingnotebook\\Predictions\\SantaMariaPredictions.txt\", \"w\")\n",
    "counter = 1\n",
    "SantaMariaString = \"\"\n",
    "\n",
    "for doc in SantaMariaPredictions:\n",
    "    SantaMariaString += \"File: \" + str(counter) + \"\\n\"\n",
    "    \n",
    "    if len(doc) > 1:\n",
    "        for pred in doc[1:]:\n",
    "            SantaMariaString += pred[0] + \": \" + pred[1] + '\\n'\n",
    "\n",
    "    SantaMariaString += \"\\n\"\n",
    "    counter+=1\n",
    "SM_txt.write(SantaMariaString)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89a09c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62614"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get predictions for Nevada County Data\n",
    "NevadaCounty = r\"C:\\Users\\Pruthvi\\Desktop\\policingnotebook\\Training Data\\Nevada County\\txt\"\n",
    "NevadaCountyPredictions = []\n",
    "for file_name in os.listdir(NevadaCounty):\n",
    "    file = open(NevadaCounty + \"\\\\\" + file_name)\n",
    "    try: \n",
    "        textarr = file.readlines()\n",
    "        textstring = ner(\" \".join(textarr))\n",
    "\n",
    "        predictions = [\"FILE NAME: \" + file_name]\n",
    "        for ent in textstring.ents:\n",
    "            \n",
    "            predictions += [[ent.text, ent.label_]]\n",
    "\n",
    "        NevadaCountyPredictions += [predictions]\n",
    "    \n",
    "    except(UnicodeDecodeError):\n",
    "        continue\n",
    "\n",
    "#Save predictions to txt file\n",
    "NC_txt = open(r\"C:\\Users\\Pruthvi\\Desktop\\policingnotebook\\Predictions\\NevadaCountyPredictions.txt\", \"w\")\n",
    "counter = 1\n",
    "NevadaCountyString = \"\"\n",
    "\n",
    "for doc in NevadaCountyPredictions:\n",
    "    NevadaCountyString += \"File: \" + str(counter) + \"\\n\"\n",
    "    \n",
    "    if len(doc) > 1:\n",
    "        for pred in doc[1:]:\n",
    "            NevadaCountyString += pred[0] + \": \" + pred[1] + '\\n'\n",
    "\n",
    "    NevadaCountyString += \"\\n\"\n",
    "    counter+=1\n",
    "NC_txt.write(NevadaCountyString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0ae70a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47967"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get predictions for Alameda County Data\n",
    "AlamedaCounty = r\"C:\\Users\\Pruthvi\\Desktop\\policingnotebook\\Training Data\\AlamedaCountyFiles\\txt\"\n",
    "AlamedaCountyPredictions = []\n",
    "for file_name in os.listdir(AlamedaCounty):\n",
    "    file = open(AlamedaCounty + \"\\\\\" + file_name)\n",
    "    try: \n",
    "        textarr = file.readlines()\n",
    "        textstring = ner(\" \".join(textarr))\n",
    "\n",
    "        predictions = [\"FILE NAME: \" + file_name]\n",
    "        for ent in textstring.ents:\n",
    "            \n",
    "            predictions += [[ent.text, ent.label_]]\n",
    "\n",
    "        AlamedaCountyPredictions += [predictions]\n",
    "    \n",
    "    except(UnicodeDecodeError):\n",
    "        continue\n",
    "\n",
    "#Save predictions to txt file\n",
    "AC_txt = open(r\"C:\\Users\\Pruthvi\\Desktop\\policingnotebook\\Predictions\\AlamedaCountyPredictions.txt\", \"w\")\n",
    "counter = 1\n",
    "AlamedaCountyString = \"\"\n",
    "\n",
    "for doc in AlamedaCountyPredictions:\n",
    "    AlamedaCountyString += \"File: \" + str(counter) + \"\\n\"\n",
    "    \n",
    "    if len(doc) > 1:\n",
    "        for pred in doc[1:]:\n",
    "            AlamedaCountyString += pred[0] + \": \" + pred[1] + '\\n'\n",
    "\n",
    "    AlamedaCountyString += \"\\n\"\n",
    "    counter+=1\n",
    "AC_txt.write(AlamedaCountyString)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
